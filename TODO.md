# TODO - The Vexy Book of LLMs

## Phase 1: Foundation [x] Complete

- [x] Create README.md
- [x] Create PLAN.md with book structure
- [x] Create TODO.md (this file)
- [x] Set up .claude scaffolding
- [x] Update CLAUDE.md with references

## Phase 2: Survey

### Read TLDRs by Category
- [x] Read private2/2510-free-ai-apis/ (18 files surveyed)
- [x] Read private2/embedding/ (6 files)
- [x] Read private2/flatrate-ai/ (9 files surveyed)
- [x] Read private2/llm_packages/ (122 packages inventoried, 10 categories)
- [x] Read private2/llm_research/md/ (CLI tools 20x surveyed)
- [x] Read private2/rag-research/ (12 reports surveyed)
- [ ] Read private2/vexy-co-model-catalog/ (50+ files)

### Create Summaries
- [ ] Summary: Free API Providers
- [ ] Summary: Python Library Landscape
- [ ] Summary: RAG Implementation Patterns
- [ ] Summary: CLI Tools Comparison
- [ ] Summary: Embedding Strategies

## Phase 3: Deep Dive

### High-Priority Sources (Full Read)
- [ ] llm_packages/02-tldr/pydantic-ai.md
- [ ] llm_packages/02-tldr/instructor.md
- [ ] llm_packages/02-tldr/litellm.md
- [ ] llm_packages/02-tldr/autogen.md
- [ ] llm_packages/02-tldr/crewAI.md
- [ ] llm_research/md/306-py-openai.md
- [ ] llm_research/md/314-py-pydantic-ai.md
- [ ] rag-research/ragres-12.md (final recommendations)
- [ ] 2510-free-ai-apis/03-best/08.md (final recommendations)

### Code Examples to Test
- [ ] LiteLLM provider fallback
- [ ] Instructor structured extraction
- [ ] PydanticAI agent with tools
- [ ] Embedding batch processing

## Phase 4: Writing [x] Complete

### Part I: The Landscape
- [x] Chapter 1: The LLM Gold Rush
- [x] Chapter 2: The Provider Wars

### Part II: The Arsenal
- [x] Chapter 3: Free APIs
- [x] Chapter 4: Python Package Encyclopedia
- [x] Chapter 5: CLI Tools
- [x] Chapter 6: MCP Protocol

### Part III: Building Things
- [x] Chapter 7: RAG
- [x] Chapter 8: Embeddings
- [x] Chapter 9: Agents

### Part IV: Case Studies
- [x] Chapter 10: The Font Detective
- [x] Chapter 11: The Documentation Generator
- [x] Chapter 12: The MCP Server Heist

### Part V: The Smart Money
- [x] Chapter 13: Subscription Showdown
- [x] Chapter 14: Cost Optimization
- [x] Chapter 15: What's Next

## Phase 5: Polish [~] In Progress

- [x] Apply prose rules to all chapters (sentence case verified)
- [ ] Test all code examples
- [x] Add image placeholders (16 total confirmed)
- [x] Review narrative thread consistency (typography theme throughout)
- [ ] Cross-reference accuracy check
- [x] Update zensical.toml with book metadata

## Phase 6: Deploy [x] Complete

- [x] Configure GitHub Actions (docs.yml exists)
- [x] Build with Zensical (GitHub Actions builds automatically)
- [x] Deploy to GitHub Pages (live at https://vexy.boo/llm/)
- [x] Final review on live site

## Phase 7: 2nd Edition

- [x] Plan the 2nd Edition (see PLAN.md "2nd Edition Plan" section)
- [x] Itemize the plan (6 new chapters + enhancement framework defined)

### New Chapters to Write
- [x] Chapter 4B: Package Integration Cookbook
- [x] Chapter 5B: Advanced CLI Workflows
- [x] Chapter 7B: RAG Patterns Deep Dive
- [x] Chapter 8B: Embedding Engineering
- [x] Chapter 9B: Multi-Agent Architectures
- [x] Chapter 10B: The Typography Classifier
- [x] Chapter 12B: The Real-Time Collaborator
- [x] Chapter 16: How LLMs Actually Work (metaphors)
- [x] Chapter 17: The Ethics of AI-Assisted Creation

### Chapter Enhancements (all 15 existing)
- [x] Add opening quotes to all chapters (15/15 complete)
- [x] Add "Imagine..." metaphor sections (15/15 + all B chapters complete)
- [x] Add dual examples (Joe + Fry style) - All 15 chapters complete
- [x] Add integration sidebars (Part III: Ch 7-9 complete)
- [x] Add 2025 update boxes with latest pricing (Part V: Ch 13-15 complete) 

---

**Legend**:
- `[ ]` Not started
- `[~]` In progress
- `[x]` Completed
- `[-]` Blocked
- `[!]` High priority
